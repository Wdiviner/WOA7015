{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cbdc92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:44:49.891442Z",
     "iopub.status.busy": "2024-01-10T17:44:49.891020Z",
     "iopub.status.idle": "2024-01-10T17:44:53.503622Z",
     "shell.execute_reply": "2024-01-10T17:44:53.502285Z"
    },
    "papermill": {
     "duration": 3.620828,
     "end_time": "2024-01-10T17:44:53.505728",
     "exception": false,
     "start_time": "2024-01-10T17:44:49.884900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from glob import glob\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # using first available GPU\n",
    "    print(\"GPU is available.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available. Switching to CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec57adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:44:53.516203Z",
     "iopub.status.busy": "2024-01-10T17:44:53.515784Z",
     "iopub.status.idle": "2024-01-10T17:44:53.521825Z",
     "shell.execute_reply": "2024-01-10T17:44:53.520870Z"
    },
    "papermill": {
     "duration": 0.013661,
     "end_time": "2024-01-10T17:44:53.524028",
     "exception": false,
     "start_time": "2024-01-10T17:44:53.510367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show images and labels\n",
    "def show_images(images, labels):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(4, 8, i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0))\n",
    "        plt.title(labels[labels[i]])\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7093c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:44:53.534421Z",
     "iopub.status.busy": "2024-01-10T17:44:53.533753Z",
     "iopub.status.idle": "2024-01-10T17:44:53.538686Z",
     "shell.execute_reply": "2024-01-10T17:44:53.537882Z"
    },
    "papermill": {
     "duration": 0.012165,
     "end_time": "2024-01-10T17:44:53.540587",
     "exception": false,
     "start_time": "2024-01-10T17:44:53.528422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义数据变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e98b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:44:53.550466Z",
     "iopub.status.busy": "2024-01-10T17:44:53.550159Z",
     "iopub.status.idle": "2024-01-10T17:44:58.042637Z",
     "shell.execute_reply": "2024-01-10T17:44:58.041866Z"
    },
    "papermill": {
     "duration": 4.50004,
     "end_time": "2024-01-10T17:44:58.045147",
     "exception": false,
     "start_time": "2024-01-10T17:44:53.545107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "# 加载图像数据集\n",
    "trainDataset = ImageFolder(root='/kaggle/input/7015-dataset/train/train', transform=transform)\n",
    "trainLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=False)\n",
    "testDataset = ImageFolder(root='/kaggle/input/7015-dataset/test/test', transform=transform)\n",
    "testLoader = DataLoader(testDataset, batch_size=batch_size, shuffle=False)\n",
    "labels = trainDataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2914505",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:44:58.055382Z",
     "iopub.status.busy": "2024-01-10T17:44:58.055042Z",
     "iopub.status.idle": "2024-01-10T17:44:58.106848Z",
     "shell.execute_reply": "2024-01-10T17:44:58.106079Z"
    },
    "papermill": {
     "duration": 0.059488,
     "end_time": "2024-01-10T17:44:58.109204",
     "exception": false,
     "start_time": "2024-01-10T17:44:58.049716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_samples = torch.tensor([]).to(device)\n",
    "train_labels = torch.tensor([]).to(device)\n",
    "test_samples = torch.tensor([]).to(device)\n",
    "test_labels = torch.tensor([]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca56209e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:44:58.119639Z",
     "iopub.status.busy": "2024-01-10T17:44:58.119308Z",
     "iopub.status.idle": "2024-01-10T17:48:56.541304Z",
     "shell.execute_reply": "2024-01-10T17:48:56.539985Z"
    },
    "papermill": {
     "duration": 238.42963,
     "end_time": "2024-01-10T17:48:56.543456",
     "exception": false,
     "start_time": "2024-01-10T17:44:58.113826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 436/436 [03:15<00:00,  2.23it/s]\n",
      "100%|██████████| 109/109 [00:43<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for images, labels in tqdm(trainLoader):\n",
    "    images = images.to(device)\n",
    "    train_samples = torch.cat([train_samples, images.unsqueeze(0)], dim=0)\n",
    "    label = list(map(lambda x: x.split('_')[1], trainDataset.class_to_idx.keys()))[labels[0]]\n",
    "    if label == 'arm':\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    train_labels = torch.cat([train_labels, torch.tensor(label).unsqueeze(0).to(device)], dim=0)\n",
    "\n",
    "for images, labels in tqdm(testLoader):\n",
    "    images = images.to(device)\n",
    "    test_samples = torch.cat([test_samples, images.unsqueeze(0)], dim=0)\n",
    "    label = list(map(lambda x: x.split('_')[1], testDataset.class_to_idx.keys()))[labels[0]]\n",
    "    if label == 'arm':\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    test_labels = torch.cat([test_labels, torch.tensor(label).unsqueeze(0).to(device)], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc66c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:48:56.639686Z",
     "iopub.status.busy": "2024-01-10T17:48:56.639345Z",
     "iopub.status.idle": "2024-01-10T17:48:56.645008Z",
     "shell.execute_reply": "2024-01-10T17:48:56.644172Z"
    },
    "papermill": {
     "duration": 0.05566,
     "end_time": "2024-01-10T17:48:56.646972",
     "exception": false,
     "start_time": "2024-01-10T17:48:56.591312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f2484",
   "metadata": {
    "papermill": {
     "duration": 0.102718,
     "end_time": "2024-01-10T17:48:56.795774",
     "exception": false,
     "start_time": "2024-01-10T17:48:56.693056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **保留resnet的fc层，除此以外冻结 1000-d向量，与lstm模型连接进行权重更新**\n",
    "2. **删除fc层，仅做特征提取cnn，不冻结，resnet部分进行fine-tuning，与lstm模型连接进行权重更新**\n",
    "3. **与光流图（optical-flow）另外一个resnet提取，提取出的特征做向量拼接**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d64e78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:48:56.891827Z",
     "iopub.status.busy": "2024-01-10T17:48:56.890786Z",
     "iopub.status.idle": "2024-01-10T17:48:56.902529Z",
     "shell.execute_reply": "2024-01-10T17:48:56.901735Z"
    },
    "papermill": {
     "duration": 0.062492,
     "end_time": "2024-01-10T17:48:56.904569",
     "exception": false,
     "start_time": "2024-01-10T17:48:56.842077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    def __init__(self, num_classes, lstm_hidden_size, lstm_num_layers, lstm_input_size):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "\n",
    "        # 加载预训练的ResNet模型\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        # 移除ResNet的最后一个全连接层，用于特征提取\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        \n",
    "#         for name, param in self.resnet.named_parameters():\n",
    "#             if \"fc\" not in name:  # 不冻结全连接层的参数\n",
    "#                 param.requires_grad = False\n",
    "\n",
    "        # LSTM模型\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=lstm_hidden_size,\n",
    "                            num_layers=lstm_num_layers, batch_first=True)\n",
    "\n",
    "        # 全连接层，用于分类\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, num_frames, C, H, W)\n",
    "        batch_size, num_frames, C, H, W = x.size()\n",
    "\n",
    "        # 将每一帧通过CNN进行特征提取\n",
    "        cnn_features = torch.zeros(batch_size, num_frames, lstm_input_size).to(x.device)\n",
    "        for i in range(num_frames):\n",
    "            frame_features = self.resnet(x[:, i, :, :, :])\n",
    "            cnn_features[:, i, :] = frame_features.squeeze(-1).squeeze(-1)\n",
    "\n",
    "        # 将特征输入LSTM模型\n",
    "        lstm_out, _ = self.lstm(cnn_features)\n",
    "\n",
    "        # 取LSTM的最后一个时间步的输出\n",
    "        lstm_last_output = lstm_out[:, -1, :]\n",
    "\n",
    "        # 全连接层\n",
    "        output = self.fc(lstm_last_output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bd876f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:48:57.001498Z",
     "iopub.status.busy": "2024-01-10T17:48:57.000688Z",
     "iopub.status.idle": "2024-01-10T17:48:57.007027Z",
     "shell.execute_reply": "2024-01-10T17:48:57.006120Z"
    },
    "papermill": {
     "duration": 0.056798,
     "end_time": "2024-01-10T17:48:57.008912",
     "exception": false,
     "start_time": "2024-01-10T17:48:56.952114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lstm_batch_size = 8\n",
    "trainDataset = myDataset(train_samples, train_labels)\n",
    "trainLoader = DataLoader(trainDataset, batch_size=lstm_batch_size, shuffle=True)\n",
    "testDataset = myDataset(test_samples, test_labels)\n",
    "testLoader = DataLoader(testDataset, batch_size=lstm_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbe36e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:48:57.103290Z",
     "iopub.status.busy": "2024-01-10T17:48:57.102571Z",
     "iopub.status.idle": "2024-01-10T17:48:57.115262Z",
     "shell.execute_reply": "2024-01-10T17:48:57.114289Z"
    },
    "papermill": {
     "duration": 0.06202,
     "end_time": "2024-01-10T17:48:57.117396",
     "exception": false,
     "start_time": "2024-01-10T17:48:57.055376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 30, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in trainLoader:\n",
    "    print(inputs.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "574e2723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:48:57.214238Z",
     "iopub.status.busy": "2024-01-10T17:48:57.213899Z",
     "iopub.status.idle": "2024-01-10T17:48:57.878230Z",
     "shell.execute_reply": "2024-01-10T17:48:57.877375Z"
    },
    "papermill": {
     "duration": 0.714901,
     "end_time": "2024-01-10T17:48:57.880537",
     "exception": false,
     "start_time": "2024-01-10T17:48:57.165636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 178MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 创建模型实例\n",
    "num_classes = 2 \n",
    "lstm_hidden_size = 4\n",
    "lstm_num_layers = 3\n",
    "lstm_input_size = 512\n",
    "model = CNNLSTM(num_classes, lstm_hidden_size, lstm_num_layers, lstm_input_size)\n",
    "model.to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b045bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-10T17:48:57.979635Z",
     "iopub.status.busy": "2024-01-10T17:48:57.978910Z",
     "iopub.status.idle": "2024-01-10T18:15:00.908847Z",
     "shell.execute_reply": "2024-01-10T18:15:00.907746Z"
    },
    "papermill": {
     "duration": 1563.030001,
     "end_time": "2024-01-10T18:15:00.959418",
     "exception": false,
     "start_time": "2024-01-10T17:48:57.929417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_0:\n",
      " training roc_auc_score 0.48226, training f1_score 0.20921, training acc 0.56651, training loss 0.62331 \n",
      " testing roc_auc_score 0.55500, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.52481 \n",
      "----------------------------------\n",
      "epoch_1:\n",
      " training roc_auc_score 0.57890, training f1_score 0.00000, training acc 0.61697, training loss 0.69267 \n",
      " testing roc_auc_score 0.35444, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.39140 \n",
      "----------------------------------\n",
      "epoch_2:\n",
      " training roc_auc_score 0.69216, training f1_score 0.34906, training acc 0.68349, training loss 0.68681 \n",
      " testing roc_auc_score 0.67833, testing f1_score 0.36364, testing acc 0.93578, testing loss 0.30779 \n",
      "----------------------------------\n",
      "epoch_3:\n",
      " training roc_auc_score 0.75766, training f1_score 0.71127, training acc 0.81193, training loss 0.24931 \n",
      " testing roc_auc_score 0.87500, testing f1_score 0.46154, testing acc 0.93578, testing loss 0.23808 \n",
      "----------------------------------\n",
      "epoch_4:\n",
      " training roc_auc_score 0.75769, training f1_score 0.72222, training acc 0.81651, training loss 0.21852 \n",
      " testing roc_auc_score 0.71333, testing f1_score 0.20000, testing acc 0.92661, testing loss 0.22493 \n",
      "----------------------------------\n",
      "epoch_5:\n",
      " training roc_auc_score 0.74566, training f1_score 0.69145, training acc 0.80963, training loss 0.54093 \n",
      " testing roc_auc_score 0.68889, testing f1_score 0.20000, testing acc 0.92661, testing loss 0.25809 \n",
      "----------------------------------\n",
      "epoch_6:\n",
      " training roc_auc_score 0.68307, training f1_score 0.67586, training acc 0.78440, training loss 0.24362 \n",
      " testing roc_auc_score 0.81667, testing f1_score 0.42857, testing acc 0.92661, testing loss 0.26051 \n",
      "----------------------------------\n",
      "epoch_7:\n",
      " training roc_auc_score 0.78141, training f1_score 0.73260, training acc 0.83257, training loss 0.17797 \n",
      " testing roc_auc_score 0.72222, testing f1_score 0.20000, testing acc 0.92661, testing loss 0.22169 \n",
      "----------------------------------\n",
      "epoch_8:\n",
      " training roc_auc_score 0.66206, training f1_score 0.31280, training acc 0.66743, training loss 0.56356 \n",
      " testing roc_auc_score 0.72667, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.40674 \n",
      "----------------------------------\n",
      "epoch_9:\n",
      " training roc_auc_score 0.75377, training f1_score 0.51639, training acc 0.72936, training loss 0.24165 \n",
      " testing roc_auc_score 0.77889, testing f1_score 0.31818, testing acc 0.72477, testing loss 0.30662 \n",
      "----------------------------------\n",
      "epoch_10:\n",
      " training roc_auc_score 0.71452, training f1_score 0.65455, training acc 0.78211, training loss 0.24110 \n",
      " testing roc_auc_score 0.50000, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.27106 \n",
      "----------------------------------\n",
      "epoch_11:\n",
      " training roc_auc_score 0.58545, training f1_score 0.24348, training acc 0.60092, training loss 0.84021 \n",
      " testing roc_auc_score 0.46500, testing f1_score 0.00000, testing acc 0.88073, testing loss 0.47361 \n",
      "----------------------------------\n",
      "epoch_12:\n",
      " training roc_auc_score 0.40431, training f1_score 0.00000, training acc 0.55963, training loss 0.70971 \n",
      " testing roc_auc_score 0.14222, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.53936 \n",
      "----------------------------------\n",
      "epoch_13:\n",
      " training roc_auc_score 0.48757, training f1_score 0.00000, training acc 0.61697, training loss 0.60230 \n",
      " testing roc_auc_score 0.82333, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.47902 \n",
      "----------------------------------\n",
      "epoch_14:\n",
      " training roc_auc_score 0.44948, training f1_score 0.00000, training acc 0.61697, training loss 0.60410 \n",
      " testing roc_auc_score 0.47000, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.48650 \n",
      "----------------------------------\n",
      "epoch_15:\n",
      " training roc_auc_score 0.44210, training f1_score 0.00000, training acc 0.61697, training loss 0.59517 \n",
      " testing roc_auc_score 0.46500, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.46288 \n",
      "----------------------------------\n",
      "epoch_16:\n",
      " training roc_auc_score 0.43706, training f1_score 0.00000, training acc 0.61697, training loss 0.72874 \n",
      " testing roc_auc_score 0.49500, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.46264 \n",
      "----------------------------------\n",
      "epoch_17:\n",
      " training roc_auc_score 0.42585, training f1_score 0.00000, training acc 0.61697, training loss 0.83306 \n",
      " testing roc_auc_score 0.53500, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.49180 \n",
      "----------------------------------\n",
      "epoch_18:\n",
      " training roc_auc_score 0.45865, training f1_score 0.00000, training acc 0.61697, training loss 0.71907 \n",
      " testing roc_auc_score 0.53500, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.48840 \n",
      "----------------------------------\n",
      "epoch_19:\n",
      " training roc_auc_score 0.48287, training f1_score 0.00000, training acc 0.61697, training loss 0.71857 \n",
      " testing roc_auc_score 0.53500, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.48622 \n",
      "----------------------------------\n",
      "epoch_20:\n",
      " training roc_auc_score 0.48877, training f1_score 0.00000, training acc 0.61697, training loss 0.60966 \n",
      " testing roc_auc_score 0.56000, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.50764 \n",
      "----------------------------------\n",
      "epoch_21:\n",
      " training roc_auc_score 0.52110, training f1_score 0.00000, training acc 0.61697, training loss 0.70777 \n",
      " testing roc_auc_score 0.16778, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.50929 \n",
      "----------------------------------\n",
      "epoch_22:\n",
      " training roc_auc_score 0.56628, training f1_score 0.00000, training acc 0.61697, training loss 0.60049 \n",
      " testing roc_auc_score 0.21167, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.59407 \n",
      "----------------------------------\n",
      "epoch_23:\n",
      " training roc_auc_score 0.55643, training f1_score 0.48125, training acc 0.61927, training loss 0.80614 \n",
      " testing roc_auc_score 0.53444, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.34410 \n",
      "----------------------------------\n",
      "epoch_24:\n",
      " training roc_auc_score 0.47343, training f1_score 0.00000, training acc 0.61697, training loss 0.47803 \n",
      " testing roc_auc_score 0.35389, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.48146 \n",
      "----------------------------------\n",
      "epoch_25:\n",
      " training roc_auc_score 0.44733, training f1_score 0.00000, training acc 0.61697, training loss 0.47336 \n",
      " testing roc_auc_score 0.50278, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.48259 \n",
      "----------------------------------\n",
      "epoch_26:\n",
      " training roc_auc_score 0.54098, training f1_score 0.00000, training acc 0.61697, training loss 0.71164 \n",
      " testing roc_auc_score 0.66278, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.46596 \n",
      "----------------------------------\n",
      "epoch_27:\n",
      " training roc_auc_score 0.54651, training f1_score 0.00000, training acc 0.61697, training loss 0.62340 \n",
      " testing roc_auc_score 0.86278, testing f1_score 0.00000, testing acc 0.91743, testing loss 0.44633 \n",
      "----------------------------------\n",
      "epoch_28:\n",
      " training roc_auc_score 0.61781, training f1_score 0.45695, training acc 0.62385, training loss 0.59481 \n",
      " testing roc_auc_score 0.88778, testing f1_score 0.33333, testing acc 0.74312, testing loss 0.30639 \n",
      "----------------------------------\n",
      "epoch_29:\n",
      " training roc_auc_score 0.79566, training f1_score 0.75578, training acc 0.78211, training loss 0.67444 \n",
      " testing roc_auc_score 0.96278, testing f1_score 0.66667, testing acc 0.92661, testing loss 0.17736 \n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 使用这个函数来设置一个全局种子\n",
    "seed_everything(42)\n",
    "\n",
    "# 初始化最佳性能指标\n",
    "least_eval_loss = 100\n",
    "\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_predict = []\n",
    "    train_label = []\n",
    "    train_predict_prob = []\n",
    "    for inputs, labels in trainLoader:\n",
    "        optimizer.zero_grad()\n",
    "        # 将数据输入模型\n",
    "        train_outputs = model(inputs.to(device))\n",
    "        _, train_predicted = torch.max(train_outputs, 1)\n",
    "        train_correct += sum(torch.argmax(train_outputs, dim=1) == labels)\n",
    "        # 计算损失\n",
    "        train_loss = criterion(train_outputs, labels.to(torch.long))\n",
    "        train_predict.extend(list(train_predicted.cpu().numpy()))\n",
    "        train_label.extend(list(labels.cpu().numpy()))\n",
    "        train_predict_prob.extend(train_outputs[:,1].cpu().detach().numpy())\n",
    "\n",
    "        # 反向传播和优化\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_predict = []\n",
    "    test_label_list = []\n",
    "    test_predict_prob = []\n",
    "    with torch.no_grad():\n",
    "        for test_inputs, test_labels in testLoader:\n",
    "            test_outputs = model(test_inputs.to(device))\n",
    "            _, test_predicted = torch.max(test_outputs, 1)\n",
    "            test_loss = criterion(test_outputs, test_labels.to(torch.long))\n",
    "            test_correct += sum(test_predicted == test_labels)\n",
    "            test_predict.extend(list(test_predicted.cpu().numpy()))\n",
    "            test_label_list.extend(list(test_labels.cpu().numpy()))\n",
    "            test_predict_prob.extend(test_outputs[:,1].cpu().numpy())\n",
    "\n",
    "    # save best model\n",
    "    if test_loss < least_eval_loss:\n",
    "        least_eval_loss = test_loss\n",
    "        torch.save(model.state_dict(), \n",
    "                   f'{epoch}_best_model_f1_{f1_score(test_label_list, test_predict):.3f}_auc_{roc_auc_score(train_label, train_predict_prob):.3f}.pth')\n",
    "\n",
    "\n",
    "    print(\n",
    "    f\"epoch_{epoch}:\\n\",\n",
    "    \"training roc_auc_score {:.5f},\".format(roc_auc_score(train_label, train_predict_prob)),\n",
    "    \"training f1_score {:.5f},\".format(f1_score(train_label, train_predict)),\n",
    "    \"training acc {:.5f},\".format(train_correct / len(trainLoader.dataset.data)),\n",
    "    \"training loss {:.5f}\".format(train_loss),\n",
    "    \"\\n\",\n",
    "    \"testing roc_auc_score {:.5f},\".format(roc_auc_score(test_label_list, test_predict_prob)),\n",
    "    \"testing f1_score {:.5f},\".format(f1_score(test_label_list, test_predict)),\n",
    "    \"testing acc {:.5f},\".format(test_correct / len(testLoader.dataset.data)),\n",
    "    \"testing loss {:.5f}\".format(test_loss),\n",
    "    \"\\n----------------------------------\"\n",
    "    )\n",
    "    \n",
    "         \n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4255503,
     "sourceId": 7330897,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1815.841882,
   "end_time": "2024-01-10T18:15:02.333346",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-10T17:44:46.491464",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
