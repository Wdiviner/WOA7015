{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9wyRX-3YuMoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v /content\n",
        "!kaggle datasets download -d wwwdiviner/7015-dataset"
      ],
      "metadata": {
        "id": "w8SRxd7ORyHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_file(zip_file_path, extract_folder):\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_folder)\n",
        "\n",
        "zip_file_path = '/content/datasets/wwwdiviner/7015-dataset/7015-dataset.zip'\n",
        "extract_folder = '/content/woa7015'\n",
        "\n",
        "unzip_file(zip_file_path, extract_folder)"
      ],
      "metadata": {
        "id": "Dsx_JlOQSHQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder, DatasetFolder\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "from glob import glob\n",
        "import gc\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torchsummary\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # using first available GPU\n",
        "    print(\"GPU is available.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available. Switching to CPU.\")"
      ],
      "metadata": {
        "id": "EnsPuCy_SP67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show images and labels\n",
        "def show_images(images, labels):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(4, 8, i + 1)\n",
        "        plt.imshow(images[i].permute(1, 2, 0))\n",
        "        plt.title(labels[labels[i]])\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CcKv7JTVSTgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define data transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "c5g7MRfuSikl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73JYZi-ZMNE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 30\n",
        "# 加载图像数据集\n",
        "trainDataset = ImageFolder(root='/content/woa7015/train/train', transform=transform)\n",
        "trainLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=False)\n",
        "testDataset = ImageFolder(root='/content/woa7015/test/test', transform=transform)\n",
        "testLoader = DataLoader(testDataset, batch_size=batch_size, shuffle=False)\n",
        "labels = trainDataset.classes"
      ],
      "metadata": {
        "id": "JEeUfKA_SinX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = torch.tensor([]).to(device)\n",
        "train_labels = torch.tensor([]).to(device)\n",
        "test_samples = torch.tensor([]).to(device)\n",
        "test_labels = torch.tensor([]).to(device)"
      ],
      "metadata": {
        "id": "-mcTO7QnSipy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKQixWEhMWat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def calculate_optical_flow(video_frames):\n",
        "    \"\"\"\n",
        "    Calculate optical flow between each pair of consecutive frames in a video.\n",
        "\n",
        "    Args:\n",
        "        video_frames (torch.Tensor): Tensor of shape (num_frames, C, H, W)\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Tensor of optical flow images of shape (num_frames-1, 2, H, W)\n",
        "    \"\"\"\n",
        "    num_frames, C, H, W = video_frames.shape\n",
        "    optical_flows = []\n",
        "\n",
        "    for i in range(num_frames - 1):\n",
        "        frame1 = video_frames[i].permute(1, 2, 0).numpy()   # Convert to (H, W, C)\n",
        "        frame2 = video_frames[i+1].permute(1, 2, 0).numpy() # Convert to (H, W, C)\n",
        "\n",
        "        # Convert frames to grayscale\n",
        "        gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
        "        gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Calculate optical flow\n",
        "        flow = cv2.calcOpticalFlowFarneback(gray1, gray2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
        "        # Convert flow to tensor and add to list\n",
        "        flow_tensor = torch.from_numpy(flow).permute(2, 0, 1) # Convert to (2, H, W)\n",
        "        optical_flows.append(flow_tensor)\n",
        "\n",
        "    return torch.stack(optical_flows)\n",
        "\n"
      ],
      "metadata": {
        "id": "fHZ_alWSLzcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num = 0\n",
        "for images, labels in tqdm(trainLoader):\n",
        "    images = images.to(device)\n",
        "    optical_flows = calculate_optical_flow(images)\n",
        "    train_samples = torch.cat([train_samples, optical_flows.unsqueeze(0)], dim=0)\n",
        "    label = list(map(lambda x: x.split('_')[1], trainDataset.class_to_idx.keys()))[labels[0]]\n",
        "    if label == 'arm':\n",
        "        label = 0\n",
        "    else:\n",
        "        label = 1\n",
        "    train_labels = torch.cat([train_labels, torch.tensor(label).unsqueeze(0).to(device)], dim=0)\n",
        "    num += 1\n",
        "    if num == 200:\n",
        "      break\n",
        "for images, labels in tqdm(testLoader):\n",
        "    images = images.to(device)\n",
        "    optical_flows = calculate_optical_flow(images)\n",
        "    test_samples = torch.cat([test_samples, optical_flows.unsqueeze(0)], dim=0)\n",
        "    label = list(map(lambda x: x.split('_')[1], testDataset.class_to_idx.keys()))[labels[0]]\n",
        "    if label == 'arm':\n",
        "        label = 0\n",
        "    else:\n",
        "        label = 1\n",
        "    test_labels = torch.cat([test_labels, torch.tensor(label).unsqueeze(0).to(device)], dim=0)\n",
        "    num += 1\n",
        "    if num == 310:\n",
        "      break"
      ],
      "metadata": {
        "id": "K90zqqPTSisc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.data[index], self.labels[index]\n"
      ],
      "metadata": {
        "id": "x50SmLASSi3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class CNNLSTM(nn.Module):\n",
        "    def __init__(self, num_classes, lstm_hidden_size, lstm_num_layers, lstm_input_size):\n",
        "        super(CNNLSTM, self).__init__()\n",
        "\n",
        "        # 加载预训练的ResNet模型\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        # 移除ResNet的最后一个全连接层，用于特征提取\n",
        "\n",
        "        # self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
        "        for name, param in self.resnet.named_parameters():\n",
        "            if \"fc\" not in name:  # 不冻结全连接层的参数\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # LSTM模型\n",
        "        self.lstm = nn.LSTM(input_size=lstm_input_size, hidden_size=lstm_hidden_size,\n",
        "                            num_layers=lstm_num_layers, batch_first=True)\n",
        "\n",
        "        # 全连接层，用于分类\n",
        "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, num_frames, C, H, W)\n",
        "        batch_size, num_frames, C, H, W = (lstm_input_size, 30, 3, 224, 224)\n",
        "\n",
        "        # 将每一帧通过CNN进行特征提取\n",
        "        cnn_features = torch.zeros(batch_size, num_frames, lstm_input_size).to(x.device)\n",
        "        for i in range(num_frames):\n",
        "            frame_features = self.resnet(x[:, i, :, :, :])\n",
        "            cnn_features[:, i, :] = frame_features.squeeze(-1).squeeze(-1)\n",
        "\n",
        "        # 将特征输入LSTM模型\n",
        "        lstm_out, _ = self.lstm(cnn_features)\n",
        "\n",
        "        # 取LSTM的最后一个时间步的输出\n",
        "        lstm_last_output = lstm_out[:, -1, :]\n",
        "\n",
        "        # 全连接层\n",
        "        output = self.fc(lstm_last_output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "-EYMOnM0LzU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_batch_size = 8\n",
        "trainDataset = myDataset(train_samples, train_labels)\n",
        "trainLoader = DataLoader(trainDataset, batch_size=lstm_batch_size, shuffle=True)\n",
        "testDataset = myDataset(test_samples, test_labels)\n",
        "testLoader = DataLoader(testDataset, batch_size=lstm_batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "NIXpv1KkSi5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, labels in trainLoader:\n",
        "  print(inputs.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "vjrnyX3HU3Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyC5LaFwWmm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建模型实例\n",
        "num_classes = 2\n",
        "lstm_hidden_size = 4\n",
        "lstm_num_layers = 3\n",
        "lstm_input_size = 1000\n",
        "model = CNNLSTM(num_classes, lstm_hidden_size, lstm_num_layers, lstm_input_size)\n",
        "model.to(device)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "ljP3FNiWS1y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchstat"
      ],
      "metadata": {
        "id": "CGDAr_UPWsHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchstat import stat\n",
        "\n",
        "stat(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "s00nKim0WrKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# 使用这个函数来设置一个全局种子\n",
        "seed_everything(42)\n",
        "\n",
        "# 初始化最佳性能指标\n",
        "least_eval_loss = 100\n",
        "\n",
        "for epoch in range(300):\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    train_predict = []\n",
        "    train_label = []\n",
        "    train_predict_prob = []\n",
        "    for inputs, labels in trainLoader:\n",
        "        optimizer.zero_grad()\n",
        "        # 将数据输入模型\n",
        "        train_outputs = model(inputs.to(device))\n",
        "        _, train_predicted = torch.max(train_outputs, 1)\n",
        "        train_correct += sum(torch.argmax(train_outputs, dim=1) == labels)\n",
        "        # 计算损失\n",
        "        train_loss = criterion(train_outputs, labels.to(torch.long))\n",
        "        train_predict.extend(list(train_predicted.cpu().numpy()))\n",
        "        train_label.extend(list(labels.cpu().numpy()))\n",
        "        train_predict_prob.extend(train_outputs[:,1].cpu().detach().numpy())\n",
        "\n",
        "        # 反向传播和优化\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_predict = []\n",
        "    test_label_list = []\n",
        "    test_predict_prob = []\n",
        "    with torch.no_grad():\n",
        "        for test_inputs, test_labels in testLoader:\n",
        "            test_outputs = model(test_inputs.to(device))\n",
        "            _, test_predicted = torch.max(test_outputs, 1)\n",
        "            test_loss = criterion(test_outputs, test_labels.to(torch.long))\n",
        "            test_correct += sum(test_predicted == test_labels)\n",
        "            test_predict.extend(list(test_predicted.cpu().numpy()))\n",
        "            test_label_list.extend(list(test_labels.cpu().numpy()))\n",
        "            test_predict_prob.extend(test_outputs[:,1].cpu().numpy())\n",
        "\n",
        "    # save best model\n",
        "    if test_loss < least_eval_loss and epoch > 10:\n",
        "        least_eval_loss = test_loss\n",
        "        torch.save(model.state_dict(),\n",
        "                   f'{epoch}_best_model_f1_{f1_score(test_label_list, test_predict):.3f}_auc_{roc_auc_score(train_label, train_predict_prob):.3f}.pth')\n",
        "\n",
        "\n",
        "    print(\n",
        "    f\"epoch_{epoch}:\\n\",\n",
        "    \"training roc_auc_score {:.5f},\".format(roc_auc_score(train_label, train_predict_prob)),\n",
        "    \"training f1_score {:.5f},\".format(f1_score(train_label, train_predict)),\n",
        "    \"training acc {:.5f},\".format(train_correct / len(trainLoader.dataset.data)),\n",
        "    \"training loss {:.5f}\".format(train_loss),\n",
        "    \"\\n\",\n",
        "    \"testing roc_auc_score {:.5f},\".format(roc_auc_score(test_label_list, test_predict_prob)),\n",
        "    \"testing f1_score {:.5f},\".format(f1_score(test_label_list, test_predict)),\n",
        "    \"testing acc {:.5f},\".format(test_correct / len(testLoader.dataset.data)),\n",
        "    \"testing loss {:.5f}\".format(test_loss),\n",
        "    \"\\n----------------------------------\"\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jIcC4XddS4wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6ABLJtlUVVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHEoK2gwhuHB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}