{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7330897,"sourceType":"datasetVersion","datasetId":4255503}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:40:03.580017Z","iopub.execute_input":"2024-01-10T06:40:03.580419Z","iopub.status.idle":"2024-01-10T06:40:16.782782Z","shell.execute_reply.started":"2024-01-10T06:40:03.580384Z","shell.execute_reply":"2024-01-10T06:40:16.781725Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder, DatasetFolder\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\nfrom glob import glob\nimport gc\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torchsummary\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")  # using first available GPU\n    print(\"GPU is available.\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU is not available. Switching to CPU.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:40:16.785205Z","iopub.execute_input":"2024-01-10T06:40:16.785601Z","iopub.status.idle":"2024-01-10T06:40:18.834819Z","shell.execute_reply.started":"2024-01-10T06:40:16.785567Z","shell.execute_reply":"2024-01-10T06:40:18.833760Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"GPU is not available. Switching to CPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"# show images and labels\ndef show_images(images, labels):\n    plt.figure(figsize=(12, 6))\n    for i in range(len(images)):\n        plt.subplot(4, 8, i + 1)\n        plt.imshow(images[i].permute(1, 2, 0))\n        plt.title(labels[labels[i]])\n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:40:18.836566Z","iopub.execute_input":"2024-01-10T06:40:18.837122Z","iopub.status.idle":"2024-01-10T06:40:18.843024Z","shell.execute_reply.started":"2024-01-10T06:40:18.837081Z","shell.execute_reply":"2024-01-10T06:40:18.842074Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# define img data transform\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:40:18.845034Z","iopub.execute_input":"2024-01-10T06:40:18.845360Z","iopub.status.idle":"2024-01-10T06:40:18.854491Z","shell.execute_reply.started":"2024-01-10T06:40:18.845331Z","shell.execute_reply":"2024-01-10T06:40:18.853699Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size = 30\n# load preparing dataset\ntrainDataset = ImageFolder(root='/kaggle/input/7015-dataset/train/train', transform=transform)\ntrainLoader = DataLoader(trainDataset, batch_size=batch_size, shuffle=False)\ntestDataset = ImageFolder(root='/kaggle/input/7015-dataset/test/test', transform=transform)\ntestLoader = DataLoader(testDataset, batch_size=batch_size, shuffle=False)\nlabels = trainDataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:40:18.855597Z","iopub.execute_input":"2024-01-10T06:40:18.855897Z","iopub.status.idle":"2024-01-10T06:40:23.444222Z","shell.execute_reply.started":"2024-01-10T06:40:18.855871Z","shell.execute_reply":"2024-01-10T06:40:23.443351Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_samples = torch.tensor([]).to(device)\ntrain_labels = torch.tensor([]).to(device)\ntest_samples = torch.tensor([]).to(device)\ntest_labels = torch.tensor([]).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:40:23.445328Z","iopub.execute_input":"2024-01-10T06:40:23.445632Z","iopub.status.idle":"2024-01-10T06:40:23.469130Z","shell.execute_reply.started":"2024-01-10T06:40:23.445607Z","shell.execute_reply":"2024-01-10T06:40:23.467868Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for images, labels in tqdm(trainLoader):\n    images = images.to(device)\n    images = (images * 255).to(torch.uint8)\n    train_samples = torch.cat([train_samples, images.unsqueeze(0)], dim=0)\n    label = list(map(lambda x: x.split('_')[1], trainDataset.class_to_idx.keys()))[labels[0]]\n    if label == 'arm':\n        label = 0\n    else:\n        label = 1\n    train_labels = torch.cat([train_labels, torch.tensor(label).unsqueeze(0).to(device)], dim=0)\nfor images, labels in tqdm(testLoader):\n    images = images.to(device)\n    images = (images * 255).to(torch.uint8)\n    test_samples = torch.cat([test_samples, images.unsqueeze(0)], dim=0)\n    label = list(map(lambda x: x.split('_')[1], testDataset.class_to_idx.keys()))[labels[0]]\n    if label == 'arm':\n        label = 0\n    else:\n        label = 1\n    test_labels = torch.cat([test_labels, torch.tensor(label).unsqueeze(0).to(device)], dim=0)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-10T06:40:23.470454Z","iopub.execute_input":"2024-01-10T06:40:23.471042Z","iopub.status.idle":"2024-01-10T06:56:55.744483Z","shell.execute_reply.started":"2024-01-10T06:40:23.471012Z","shell.execute_reply":"2024-01-10T06:56:55.742996Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 436/436 [14:52<00:00,  2.05s/it]\n100%|██████████| 109/109 [01:39<00:00,  1.10it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_samples = train_samples.to('cpu')\ntest_samples = test_samples.to('cpu')","metadata":{"execution":{"iopub.status.busy":"2024-01-09T03:00:41.903376Z","iopub.execute_input":"2024-01-09T03:00:41.903731Z","iopub.status.idle":"2024-01-09T03:00:50.012707Z","shell.execute_reply.started":"2024-01-09T03:00:41.903698Z","shell.execute_reply":"2024-01-09T03:00:50.011810Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# clear the unusage cache\ntorch.cuda.empty_cache()\ntorch.cuda.reset_peak_memory_stats()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:01:26.105173Z","iopub.execute_input":"2024-01-10T07:01:26.105724Z","iopub.status.idle":"2024-01-10T07:01:26.552628Z","shell.execute_reply.started":"2024-01-10T07:01:26.105689Z","shell.execute_reply":"2024-01-10T07:01:26.551076Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# clear the unusage cache\u001b[39;00m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_peak_memory_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/cuda/memory.py:281\u001b[0m, in \u001b[0;36mreset_peak_memory_stats\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the \"peak\" stats tracked by the CUDA memory allocator.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \n\u001b[1;32m    268\u001b[0m \u001b[38;5;124;03mSee :func:`~torch.cuda.memory_stats` for details. Peak stats correspond to the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03m    management.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_resetPeakMemoryStats\u001b[49m(device)\n","\u001b[0;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_resetPeakMemoryStats'"],"ename":"AttributeError","evalue":"module 'torch._C' has no attribute '_cuda_resetPeakMemoryStats'","output_type":"error"}]},{"cell_type":"code","source":"class simple3dConv(nn.Module):\n    def __init__(self, num_classes):\n        super(simple3dConv, self).__init__()\n        self.net = nn.Sequential(\n        nn.Conv3d(3, 64, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool3d(2),\n        nn.BatchNorm3d(64),\n\n#         nn.Conv3d(64, 64, kernel_size=3),\n#         nn.ReLU(),\n#         nn.MaxPool3d(2),\n#         nn.BatchNorm3d(64),\n\n        nn.Conv3d(64, 128, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool3d(2),\n        nn.BatchNorm3d(128),\n\n        nn.Conv3d(128, 256, kernel_size=3),\n        nn.ReLU(),\n        nn.MaxPool3d(2),\n        nn.BatchNorm3d(256),\n            \n        nn.AdaptiveAvgPool3d((1,1,1)),\n            \n        nn.Flatten(),\n        nn.Linear(256, 512),\n        nn.ReLU(),\n        \n        nn.Dropout(0.3),\n        nn.Linear(512, num_classes)\n        )\n    def forward(self, x):\n        x = self.net(x)\n        return x\n    \nclass myDataset(Dataset):\n    def __init__(self, data, labels):\n        self.data = data\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        return self.data[index], self.labels[index]","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:01:38.491305Z","iopub.execute_input":"2024-01-10T07:01:38.495670Z","iopub.status.idle":"2024-01-10T07:01:38.536151Z","shell.execute_reply.started":"2024-01-10T07:01:38.495401Z","shell.execute_reply":"2024-01-10T07:01:38.531960Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CNN_batch_size = 8\ntraindataset3d = myDataset(train_samples, train_labels)\ntraindataloader3d = DataLoader(traindataset3d, batch_size=CNN_batch_size, shuffle=True)\ntestdataset3d = myDataset(test_samples, test_labels)\ntestdataloader3d = DataLoader(testdataset3d, batch_size=CNN_batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:01:40.853268Z","iopub.execute_input":"2024-01-10T07:01:40.855514Z","iopub.status.idle":"2024-01-10T07:01:40.874250Z","shell.execute_reply.started":"2024-01-10T07:01:40.855335Z","shell.execute_reply":"2024-01-10T07:01:40.869830Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ExponentialLR\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\ninitial_learning_rate = 3e-5\n# decay_steps = 10\n# decay_rate = 0.96\nepochs = 80\nnum_classes = 2\n\nmodel = simple3dConv(num_classes).to(device)\n# 定义损失函数和优化器\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=initial_learning_rate)\n\n# lr_scheduler = ExponentialLR(optimizer, gamma=decay_rate)\nscheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:01:42.422040Z","iopub.execute_input":"2024-01-10T07:01:42.424000Z","iopub.status.idle":"2024-01-10T07:01:42.502855Z","shell.execute_reply.started":"2024-01-10T07:01:42.423833Z","shell.execute_reply":"2024-01-10T07:01:42.500566Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import gc\ndel train_samples, test_samples\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:01:43.642292Z","iopub.execute_input":"2024-01-10T07:01:43.645775Z","iopub.status.idle":"2024-01-10T07:01:44.037856Z","shell.execute_reply.started":"2024-01-10T07:01:43.645505Z","shell.execute_reply":"2024-01-10T07:01:44.034556Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"211"},"metadata":{}}]},{"cell_type":"code","source":"torchsummary.summary(model, (3,30,224,224))","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:01:45.872567Z","iopub.execute_input":"2024-01-10T07:01:45.874867Z","iopub.status.idle":"2024-01-10T07:01:56.176106Z","shell.execute_reply.started":"2024-01-10T07:01:45.874645Z","shell.execute_reply":"2024-01-10T07:01:56.172497Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv3d-1     [-1, 64, 28, 222, 222]           5,248\n              ReLU-2     [-1, 64, 28, 222, 222]               0\n         MaxPool3d-3     [-1, 64, 14, 111, 111]               0\n       BatchNorm3d-4     [-1, 64, 14, 111, 111]             128\n            Conv3d-5    [-1, 128, 12, 109, 109]         221,312\n              ReLU-6    [-1, 128, 12, 109, 109]               0\n         MaxPool3d-7       [-1, 128, 6, 54, 54]               0\n       BatchNorm3d-8       [-1, 128, 6, 54, 54]             256\n            Conv3d-9       [-1, 256, 4, 52, 52]         884,992\n             ReLU-10       [-1, 256, 4, 52, 52]               0\n        MaxPool3d-11       [-1, 256, 2, 26, 26]               0\n      BatchNorm3d-12       [-1, 256, 2, 26, 26]             512\nAdaptiveAvgPool3d-13         [-1, 256, 1, 1, 1]               0\n          Flatten-14                  [-1, 256]               0\n           Linear-15                  [-1, 512]         131,584\n             ReLU-16                  [-1, 512]               0\n          Dropout-17                  [-1, 512]               0\n           Linear-18                    [-1, 2]           1,026\n================================================================\nTotal params: 1,245,058\nTrainable params: 1,245,058\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 17.23\nForward/backward pass size (MB): 1876.24\nParams size (MB): 4.75\nEstimated Total Size (MB): 1898.22\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport os\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# 使用这个函数来设置一个全局种子\nseed_everything(42)\n\nfor epoch in range(epochs):\n    model.train()\n    train_correct = 0\n    train_loss = []\n    for inputs, labels in traindataloader3d:\n        optimizer.zero_grad()\n\n        inputs = torch.permute(inputs,(0, 2, 1, 3, 4))\n\n        # 将数据输入模型\n        outputs = model(inputs.to(device))\n        \n        train_correct += sum(torch.argmax(outputs, dim=1) == labels)\n        # 计算损失\n        batch_loss = criterion(outputs, labels.to(torch.long))\n        train_loss.append(batch_loss)\n        # 反向传播和优化\n        batch_loss.backward()\n        optimizer.step()\n        scheduler.step()\n    model.eval()\n    test_correct = 0\n    test_loss = []\n    with torch.no_grad():\n        for inputs, labels in testdataloader3d:\n            inputs = torch.permute(inputs,(0, 2, 1, 3, 4))\n            outputs = model(inputs.to(device))\n            predicted_labels = torch.argmax(outputs, dim=1)\n            test_loss.append(criterion(outputs, labels.to(torch.long)))\n            test_correct += sum(predicted_labels == labels)\n            print(torch.argmax(outputs, dim=1), labels)\n\n    print(\"training acc {:.5f}\".format(train_correct / len(traindataloader3d.dataset.data)),\n          \"training loss {:.5f}\".format(torch.mean(torch.tensor(train_loss)).item()),\n          \"----------------\",\n          \"testing acc {:.5f}\".format(test_correct / len(testdataloader3d.dataset.data)),\n          \"testing loss {:.5f}\".format(torch.mean(torch.tensor(test_loss)).item()),\n         )\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-01-10T07:01:59.014150Z","iopub.execute_input":"2024-01-10T07:01:59.014575Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"tensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 1, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 1, 1, 1, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 1, 1, 0, 1, 1, 1]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([1, 1, 0, 1, 0, 1, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.89220 training loss 0.50344 ---------------- testing acc 0.79817 testing loss 0.53948\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 1, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 1, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([1, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.93578 training loss 0.34020 ---------------- testing acc 0.88991 testing loss 0.45847\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.93349 training loss 0.27327 ---------------- testing acc 0.91743 testing loss 0.46219\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([1, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.95642 training loss 0.22202 ---------------- testing acc 0.90826 testing loss 0.40974\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.96789 training loss 0.19300 ---------------- testing acc 0.91743 testing loss 0.44363\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.97018 training loss 0.16516 ---------------- testing acc 0.91743 testing loss 0.38902\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.97477 training loss 0.12769 ---------------- testing acc 0.91743 testing loss 0.46915\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.98624 training loss 0.11827 ---------------- testing acc 0.91743 testing loss 0.44325\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.98853 training loss 0.08983 ---------------- testing acc 0.91743 testing loss 0.46888\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.98853 training loss 0.08725 ---------------- testing acc 0.91743 testing loss 0.44222\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.99541 training loss 0.06353 ---------------- testing acc 0.91743 testing loss 0.50408\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 1., 1., 1., 1., 1., 1., 1.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([1., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0., 0., 0., 0.])\ntensor([0, 0, 0, 0, 0]) tensor([0., 0., 0., 0., 0.])\ntraining acc 0.98853 training loss 0.05511 ---------------- testing acc 0.91743 testing loss 0.51828\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}